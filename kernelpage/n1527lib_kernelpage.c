/* n1527lib_kernelpage.c
A kernel page implementation of the N1527 proposal for the C programming language
(C) 2011 Niall Douglas http://www.nedproductions.biz/


Boost Software License - Version 1.0 - August 17th, 2003

Permission is hereby granted, free of charge, to any person or organization
obtaining a copy of the software and accompanying documentation covered by
this license (the "Software") to use, reproduce, display, distribute,
execute, and transmit the Software, and to prepare derivative works of the
Software, and to permit third-parties to whom the Software is furnished to
do so, all subject to the following:

The copyright notices in the Software and this entire statement, including
the above license grant, this restriction and the following disclaimer,
must be included in all copies of the Software, in whole or in part, and
all derivative works of the Software, unless such copies or derivative
works are solely in the form of machine-executable object code generated by
a source language processor.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
DEALINGS IN THE SOFTWARE.
*/

#include "../n1527lib.h"
#include <string.h>
#include <errno.h>
#include <malloc.h>
#ifdef WIN32
#define WIN32_LEAN_AND_MEAN 1
#include "windows.h"
#else
#include <unistd.h>
#endif
#include "../nedtries/nedtrie.h"

#define BLOCKMETADATASTORAGECHUNK 65536

struct mpool_s {
  struct mpool_APIset *APIset;   /* This HAS to be here! */
};
static struct mpool_s kernelpagepool;
static size_t AlignmentsAndRoundings[]={
  /* page size */ 0,
  /* large page size? */ 0,
  0
};

/* Set up the blockmetadata indexing */
typedef struct blockmetadata_s blockmetadata_t;
struct blockmetadata_s
{
  NEDTRIE_ENTRY(blockmetadata_s) link;
  void *block;
  size_t size;
};
typedef struct blockmetadata_tree_s blockmetadata_tree_t;
NEDTRIE_HEAD(blockmetadata_tree_s, blockmetadata_t);
static blockmetadata_tree_t blockmetadata_tree;
static size_t blockmetadatakeyfunct(const blockmetadata_t *r)
{
  return (size_t) r->block;
}
NEDTRIE_GENERATE(static, blockmetadata_tree_s, blockmetadata_s, link, blockmetadatakeyfunct, NEDTRIE_NOBBLEZEROS(blockmetadata_tree_s));
/* Set up the blockmetadata storage */
typedef struct blockmetadatastorage_s blockmetadatastorage_t;
struct blockmetadatastorage_s
{
  blockmetadatastorage_t *next;
  blockmetadata_t storage[(BLOCKMETADATASTORAGECHUNK-sizeof(void *))/sizeof(blockmetadata_t)];
};
static blockmetadatastorage_t *blockmetadatastorage;
static blockmetadata_t *freeblockmetadata;
static int NewBlockMetaDataStorage(void)
{
  blockmetadatastorage_t *storage;
  size_t n;
#ifdef WIN32
  if(!(storage=VirtualAlloc(NULL, BLOCKMETADATASTORAGECHUNK, MEM_RESERVE|MEM_COMMIT, PAGE_READWRITE)))
    return 0;
#else
  if(!(storage=mmap(NULL, BLOCKMETADATASTORAGECHUNK, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0)))
    return 0;
#endif
  storage->next=blockmetadatastorage;
  blockmetadatastorage=storage;
  for(n=0; n<sizeof(storage->storage)/sizeof(blockmetadata_t); n++)
  {
    blockmetadata_t *item=&storage->storage[n];
    item->block=freeblockmetadata;
    freeblockmetadata=item;
  }
  return 1;
}
static blockmetadata_t *NewBlockMetaData(void)
{
  blockmetadata_t *ret;
  if(!freeblockmetadata)
  {
    if(!NewBlockMetaDataStorage())
      return 0;
  }
  ret=freeblockmetadata;
  freeblockmetadata=(blockmetadata_t *) freeblockmetadata->block;
  return ret;
}
static void FreeBlockMetaData(blockmetadata_t *bmd)
{
  bmd->block=freeblockmetadata;
  freeblockmetadata=bmd;
}

static int rateattributes(const size_t *RESTRICT alignments[], const size_t *RESTRICT roundings[], const struct mpool_attribute_data **RESTRICT attributes);
static mpool createpool(struct mpool_attribute_data **RESTRICT attributes, mpool systempool);
static void destroypool(mpool pool);
static N1527MALLOCNOALIASATTR N1527MALLOCPTRATTR void **_batch(mpool pool, int *errnos, void **ptrs, size_t *RESTRICT sizes, size_t *RESTRICT count, uintmax_t flags);
static N1527MALLOCNOALIASATTR N1527MALLOCPTRATTR void *_calloc(mpool pool, size_t nmemb, size_t size);
static void _free(mpool pool, void *ptr);
static N1527MALLOCNOALIASATTR N1527MALLOCPTRATTR void *_malloc(mpool pool, size_t size);
static N1527MALLOCNOALIASATTR N1527MALLOCPTRATTR void *_realloc(mpool pool, void *ptr, size_t size);
static N1527MALLOCNOALIASATTR N1527MALLOCPTRATTR void *_try_realloc(mpool pool, void *ptr, size_t size);
static size_t _usable_size(mpool pool, void *ptr);
static mpool _ownerpool(void *ptr);
static struct mpool_APIset kernelpage_apiset = {
  rateattributes,
  createpool,
  destroypool,
  _batch,
  _calloc,
  _free,
  _malloc,
  _realloc,
  _try_realloc,
  _usable_size,
  _ownerpool,
};


#ifdef _MSC_VER
__declspec(dllexport)
#else
__attribute__ ((visibility("default")))
#endif
struct mpool_APIset kernelpage_allocator_APIset(void)
{
  return kernelpage_apiset;
}

int rateattributes(const size_t *RESTRICT alignments[], const size_t *RESTRICT roundings[], const struct mpool_attribute_data **RESTRICT attributes)
{
  struct mpool_s *m=&kernelpagepool;
  int score=0;
  if(alignments) *alignments=AlignmentsAndRoundings;
  if(roundings) *roundings=AlignmentsAndRoundings;
  if(!m->APIset)
  {
    m->APIset=&kernelpage_apiset;
#ifdef WIN32
    {
      SYSTEM_INFO si={0};
      GetSystemInfo(&si);
      AlignmentsAndRoundings[0]=si.dwPageSize;
    }
#else
    AlignmentsAndRoundings[0]=getpagesize();
#endif
    NEDTRIE_INIT(&blockmetadata_tree);
    NewBlockMetaDataStorage();
  }
  if(attributes)
  {
    for(; *attributes; attributes++)
    {
      switch((*attributes)->id)
      {
      case MPOOL_ATTRIBUTE_DESTROYUNUSED:
        { /* Kernel always destroys deallocated memory, so this is good */
          score++;
          break;
        }
      case MPOOL_ATTRIBUTE_ALIGNMENT:
        {
          struct mpool_attribute_alignment *a=(struct mpool_attribute_alignment *) *attributes;
          if(a->alignment & (AlignmentsAndRoundings[0]-1))
          { /* Instant fail */
            return INT_MIN;
          }
          score+=AlignmentsAndRoundings[0];
          break;
        }
      case MPOOL_ATTRIBUTE_SIZEROUNDING:
        {
          struct mpool_attribute_sizerounding *a=(struct mpool_attribute_sizerounding *) *attributes;
          if(a->rounding & (AlignmentsAndRoundings[0]-1))
          { /* Instant fail */
            return INT_MIN;
          }
          score+=AlignmentsAndRoundings[0];
          break;
        }
      case MPOOL_ATTRIBUTE_USESYSTEMPOOL:
        {
          struct mpool_attribute_usesystempool *a=(struct mpool_attribute_usesystempool *) *attributes;
          /* Instant fail */
          return INT_MIN;
        }
      }
    }
  }
  return score;
}

mpool createpool(struct mpool_attribute_data **RESTRICT attributes, mpool systempool)
{ /* The kernelpage allocator is a little unusual - it only has one pool! */
  struct mpool_s *m=&kernelpagepool;
  int ok=0;
  assert(m->APIset);
  /* Fail if he doesn't ask for an aligned multiple of the page size with page size rounding */
  if(!attributes) return 0;
  for(; *attributes; attributes++)
  {
    switch((*attributes)->id)
    {
    case MPOOL_ATTRIBUTE_DESTROYUNUSED:
      { /* Kernel always destroys deallocated memory, so this is good */
        break;
      }
    case MPOOL_ATTRIBUTE_ALIGNMENT:
      {
        struct mpool_attribute_alignment *a=(struct mpool_attribute_alignment *) *attributes;
        if(a->alignment & (AlignmentsAndRoundings[0]-1))
          a->error=EACCES;
        else
          ok|=1;
        break;
      }
    case MPOOL_ATTRIBUTE_SIZEROUNDING:
      {
        struct mpool_attribute_sizerounding *a=(struct mpool_attribute_sizerounding *) *attributes;
        if(a->rounding & (AlignmentsAndRoundings[0]-1))
          a->error=EACCES;
        else
          ok|=2;
        break;
      }
      case MPOOL_ATTRIBUTE_USESYSTEMPOOL:
        {
          struct mpool_attribute_usesystempool *a=(struct mpool_attribute_usesystempool *) *attributes;
          /* Instant fail */
          a->error=EACCES;
          ok|=4;
          break;
        }
    default:
      {
        (*attributes)->error=ENOENT;
      }
    }
  }
  return (3==ok) ? m : 0;
}

void destroypool(mpool pool)
{
  /* Does nothing */
}

FORCEINLINE N1527MALLOCNOALIASATTR N1527MALLOCPTRATTR void **_batch(mpool pool, int *errnos, void **ptrs, size_t *RESTRICT sizes, size_t *RESTRICT count, uintmax_t flags)
{
  struct mpool_s *m=&kernelpagepool;
  size_t maxn=*count, _count=0, n;
  uintmax_t combinedflags=flags;
  blockmetadata_t f={0}, *bmd;
  /* Sanity check the mpool */
  assert(m->APIset);
  if((mpool) m!=pool) return 0;
  /* We also don't support ptrs being null */
  if(!ptrs) return 0;
  for(n=0; n<maxn; n++)
  {
    if(ptrs[n])
    {
      f.block=ptrs[n];
      bmd=NEDTRIE_FIND(blockmetadata_tree_s, &blockmetadata_tree, &f);
      if(!bmd)
      { /* Unknown block */
        if(errnos) errnos[n]=EFAULT;
        continue;
      }
      else
      {
        assert(bmd->block==ptrs[n]);
      }
    }
    else bmd=0;
    if(!sizes) /* free */
    {
#ifdef WIN32
      if(!VirtualFree(ptrs[n], 0, MEM_RELEASE))
      {
        if(errnos) errnos[n]=EINVAL;
      }
#else
      if(munmap(ptrs[n], md->size))
      {
        if(errnos) errnos[n]=errno;
      }
#endif
      else
      {
        ptrs[n]=0;
        NEDTRIE_REMOVE(blockmetadata_tree_s, &blockmetadata_tree, bmd);
        FreeBlockMetaData(bmd);
        bmd=0;
        _count++;
      }
    }
    else if(!ptrs[n]) /* malloc */
    {
#ifdef WIN32
      DWORD vaflags=MEM_RESERVE|MEM_COMMIT;
      if(flags & MPOOL_HIGH_ADDR) vaflags|=MEM_TOP_DOWN;
      if(!(ptrs[n]=VirtualAlloc(NULL, sizes[n], vaflags, PAGE_READWRITE)))
      {
        if(errnos) errnos[n]=EINVAL;
      }
#else
      int vaflags=MAP_PRIVATE|MAP_ANONYMOUS;
      if(flags & MPOOL_HIGH_ADDR) vaflags|=MAP_GROWSDOWN;
      if(!(ptrs[n]=mmap(NULL, sizes[n], PROT_READ|PROT_WRITE, vaflags, -1, 0)))
      {
        if(errnos) errnos[n]=errno;
      }
#endif
      else
      {
        bmd=NewBlockMetaData();
        bmd->block=ptrs[n];
        bmd->size=sizes[n];
        NEDTRIE_INSERT(blockmetadata_tree_s, &blockmetadata_tree, bmd);
        _count++;
      }
    }
    else /* realloc */
    {
      void *temp=0;
      size_t tocopy=(sizes[n]<bmd->size) ? sizes[n] : bmd->size;
#ifdef __linux__
      if(!(temp=mremap(ptrs[n], bmd->size, sizes[n], (flags & MPOOL_PREVENT_MOVE) ? 0 : MREMAP_MAYMOVE)))
      {
        if(errnos) errnos[n]=(ENOMEM==errno && (flags & MPOOL_PREVENT_MOVE)) ? ENOSPC : errno;
      }
#else
      if(flags & MPOOL_PREVENT_MOVE)
      {
        if(errnos) errnos[n]=ENOSPC;
#ifdef __GNUC__
#warning In place kernel page allocation resizing not implemented yet
#endif
#ifdef _MSC_VER
#pragma message(__FILE__ ": WARNING: In place kernel page allocation resizing not implemented yet")
#endif
      }
      else
      {
        void *temp;
#ifdef WIN32
        if(!(temp=VirtualAlloc(NULL, sizes[n], MEM_RESERVE|MEM_COMMIT, PAGE_READWRITE)))
        {
          if(errnos) errnos[n]=EINVAL;
        }
#else
        if(!(temp=mmap(NULL, sizes[n], PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0)))
        {
          if(errnos) errnos[n]=errno;
        }
#endif
        else
        {
          memcpy(temp, ptrs[n], tocopy);
#ifdef WIN32
          VirtualFree(ptrs[n], 0, MEM_RELEASE);
#else
          munmap(ptrs[n], bmd->size);
#endif
          ptrs[n]=0;
        }
      }
#endif /* linux | not linux */
      if(temp)
      {
        /*if(flags & MPOOL_ZERO_MEMORY)*/ /* don't need this */
        if(temp!=ptrs[n])
        {
          NEDTRIE_REMOVE(blockmetadata_tree_s, &blockmetadata_tree, bmd);
          bmd->block=temp;
          NEDTRIE_INSERT(blockmetadata_tree_s, &blockmetadata_tree, bmd);
        }
        bmd->size=sizes[n];
        ptrs[n]=temp;
        _count++;
      }
    }
  }

  *count=_count;
  return ptrs;
}     

/* Make the compiler generate specialised versions for each of these */
N1527MALLOCNOALIASATTR N1527MALLOCPTRATTR void *_calloc(mpool pool, size_t nmemb, size_t size)
{
  void *ret=0;
  size_t count=1;
  /* Overflow check already done for us */
  size*=nmemb;
  return _batch(pool, NULL, &ret, &size, &count, MPOOL_ZERO_MEMORY), ret;
}
void _free(mpool pool, void *ptr)
{
  size_t count=1;
  _batch(pool, NULL, &ptr, NULL, &count, 0);
}
N1527MALLOCNOALIASATTR N1527MALLOCPTRATTR void *_malloc(mpool pool, size_t size)
{
  void *ret=0;
  size_t count=1;
  return _batch(pool, NULL, &ret, &size, &count, 0), ret;
}
N1527MALLOCNOALIASATTR N1527MALLOCPTRATTR void *_realloc(mpool pool, void *ptr, size_t size)
{
  size_t count=1;
  return _batch(pool, NULL, &ptr, &size, &count, 0), ptr;
}
N1527MALLOCNOALIASATTR N1527MALLOCPTRATTR void *_try_realloc(mpool pool, void *ptr, size_t size)
{
  size_t count=1;
  return _batch(pool, NULL, &ptr, &size, &count, MPOOL_PREVENT_MOVE), ptr;
}
size_t _usable_size(mpool pool, void *ptr)
{
  blockmetadata_t f={0}, *bmd;
  f.block=ptr;
  bmd=NEDTRIE_FIND(blockmetadata_tree_s, &blockmetadata_tree, &f);
  return bmd ? bmd->size : 0;
}
mpool _ownerpool(void *ptr)
{
  struct mpool_s *m=0;
#ifdef __GNUC__
#warning ownerpool() not yet implemented
#endif
#ifdef _MSC_VER
#pragma message(__FILE__ ": WARNING: ownerpool() not yet implemented")
#endif
  return NULL;
}

